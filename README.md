# Análisis de Taxis y Emisiones de CO2 en la Ciudad de Nueva York

## Descripción del Proyecto
Este proyecto tiene como objetivo proporcionar un análisis detallado sobre el mercado de taxis en la ciudad de Nueva York, centrándose en aspectos clave como la cuota de mercado entre taxis amarillos y verdes, el consumo de combustible, la rentabilidad por kilometraje de batería y las mediciones de ozono. El análisis está diseñado para brindar información valiosa a empresas interesadas en ingresar a este mercado.

## Key Performance Indicators (KPIs)

### 1. Comparación de la Cuota de Mercado
El KPI de cuota de mercado compara la participación de mercado entre taxis amarillos y verdes en la ciudad de Nueva York. Este indicador proporciona información crucial sobre la competencia en el sector.

### 2. Promedio de Consumo de Combustible
Este KPI evalúa el consumo promedio de combustible tanto en entornos urbanos como en carreteras. Proporciona información esencial para comprender la eficiencia energética de los vehículos.

### 3. Rentabilidad por Kilometraje de Batería
El KPI de rentabilidad por kilometraje de batería analiza la eficiencia y rentabilidad de los vehículos eléctricos en comparación con los vehículos de combustión interna.

### 4. Medición de Ozono
Este KPI evalúa las mediciones de ozono en áreas específicas de la ciudad de Nueva York. Proporciona información sobre la calidad del aire y la sostenibilidad de los vehículos.

## Metodología

El análisis se lleva a cabo en un período de cuatro semanas, distribuido de la siguiente manera:

### Semana 1: Comprensión de la Problemática y Definición de Objetivos
En esta etapa inicial, se enfoca en comprender a fondo la problemática, establecer los objetivos específicos del proyecto y poner en marcha las actividades necesarias.

### Semana 2: Análisis Profundo de los Datos e Informes
Durante la segunda semana, se realiza un análisis exhaustivo de los datos recopilados y se generan informes detallados para obtener una comprensión completa del panorama actual.

### Semana 3: Selección, Preparación y Entrenamiento de un Modelo de Machine Learning
En esta etapa, se selecciona un modelo de machine learning adecuado, se preparan los datos y se procede a entrenar el modelo para llevar a cabo las predicciones y análisis necesarios.

### Semana 4: Entrega del Análisis Completo, Funcional y Documentado
En la última semana, se finaliza el análisis, se verifica su funcionalidad y se documenta de manera detallada para su presentación a la empresa interesada.


## Herramientas Utilizadas

### Python
Python es la columna vertebral de nuestro proyecto, respaldado por librerías esenciales como Pandas, Numpy, Seaborn y Matplotlib. Aprovechamos la comodidad de trabajar con las Jupyter Notebooks para realizar transformaciones de datos (ETL) y llevar a cabo análisis exploratorio de los datos (EDA).

### Google Cloud Platform (GCP)
GCP se destaca como una de las principales plataformas de servicios en la nube, y hemos elegido esta plataforma para alojar y gestionar nuestros datos y aplicaciones por varias razones fundamentales:

- **Escalabilidad y Flexibilidad:** GCP ofrece una amplia variedad de servicios que nos permiten escalar nuestras aplicaciones y recursos de manera eficiente. Podemos ajustar nuestros recursos según nuestras necesidades, lo cual es particularmente beneficioso para proyectos que experimentan fluctuaciones en la demanda.

- **Potencia y Rendimiento:** GCP se basa en la infraestructura de Google, reconocida por su velocidad y capacidad de procesamiento. Esto ha facilitado nuestra colaboración en la nube como una alternativa eficiente a trabajar de manera local.

- **Machine Learning e Inteligencia Artificial:** GCP nos brinda herramientas predefinidas por Google para implementar soluciones de Machine Learning e Inteligencia Artificial.

- **Big Data y Análisis Avanzado:** GCP proporciona servicios y herramientas sólidas para el procesamiento de big data, como BigQuery, que hemos aprovechado para nuestras necesidades de análisis avanzado.


## Roles

En nuestro proyecto, contamos con cuatro roles fundamentales:

### Data Scientist
- **Maria Leiton**
- **Joaquin Amarilla**

Los Data Scientists son figuras clave en nuestro equipo y desempeñan un papel fundamental en la generación de conocimientos a partir de los datos.

### Data Analysts
Los Data Analysts en nuestro equipo se dedican principalmente a tareas relacionadas con el análisis de datos. Dos de los miembros que desempeñan este rol son:

- **Oswaldo Garcia**
- **Mariano Acosta**

Estos profesionales son responsables de extraer, limpiar, analizar y presentar datos de una manera significativa para tomar decisiones informadas.

### Data Engineers
Los Data Engineers en nuestro equipo se centran principalmente en tareas relacionadas con la ingeniería de datos. 
- **Nicolas Aranda**

Se encargaa de diseñar, implementar y mantener las infraestructuras de datos y pipelines que permiten la recopilación, procesamiento y almacenamiento eficiente de los datos.


